{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the upload file to MTG tool and Game issue list\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "        \n",
    "def upload_file():\n",
    "    wd = os.getcwd()\n",
    "    path=os.path.join(wd,'splunk')\n",
    "    allfile=os.listdir(path)\n",
    "    files = [os.path.join(path,files) for files in allfile if re.search(r'(\\d{2}\\.csv$)', files)]\n",
    "\n",
    "    my_data_0=pd.DataFrame()\n",
    "    my_data_1=pd.DataFrame()\n",
    "\n",
    "    for i in files:\n",
    "        df=pd.read_csv(os.path.join(path,i))\n",
    "    #df1=df[(df['file'] == 'index.html') | (df['file'] == 'analytics.html')]\n",
    "        df1=df.loc[df['file'].isin(['index.html','analytics.html'])]\n",
    "        my_data_0=my_data_0.append(df,sort=False)\n",
    "        my_data_1=my_data_1.append(df1,sort=False)\n",
    "        \n",
    "    file1=os.path.join(path,'Merge.csv')\n",
    "    file2=os.path.join(path,'MergedFiltered.csv')\n",
    "\n",
    "    open(file1, 'w').close()\n",
    "    open(file2, 'w').close()    \n",
    "\n",
    "    my_data_0.to_csv(os.path.join(path,'Merge.csv'),index=False)\n",
    "    my_data_1.to_csv(os.path.join(path,'MergedFiltered.csv'),index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "def game_sum():\n",
    "    wd = os.getcwd()\n",
    "    path=os.path.join(wd,'Initial')\n",
    "    filelist = os.listdir(path)\n",
    "    files = [os.path.join(path,files) for files in filelist if files.endswith('.json')]\n",
    "    mydf=pd.DataFrame()\n",
    "\n",
    "    for i in files:\n",
    "    #Read Joson File\n",
    "        df = pd.read_json(i)\n",
    "        df=df.loc[:,['id','title', 'issues']].set_index('id')\n",
    "        df1 = pd.DataFrame([[np.nan] * len(df.columns)], columns=df.columns,index=df.index.unique())\n",
    "\n",
    "        folder=str(df.index.unique()[0])\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "        mydf=mydf.append(df)\n",
    "        mydf=mydf.append(df1)\n",
    "     \n",
    "    Re = mydf.issues.notna()\n",
    "    a=mydf['issues'].mask(Re, '\"' + mydf['issues'] + '\"')\n",
    "    b = pd.Series('', index=a.index).mask(mydf.issues.shift(-1).notna()& Re, ',')\n",
    "    mydf['issues_v1'] = (a + b)\n",
    "    \n",
    "    new_df=mydf[['title','issues']].dropna().reset_index().set_index(['id','title'])\n",
    "    counts = new_df.groupby(level=0).cumcount()\n",
    "    df2=new_df.set_index(counts, append=True).iloc[:,0].unstack()\n",
    "    \n",
    "    df2=df2.reset_index()\n",
    "    df2['id']='MTG_'+df2['id'].astype(str)\n",
    "\n",
    "\n",
    "    mydf.to_csv('Games For This Week.csv')\n",
    "    df2.to_csv('Games Issues This Week.csv')\n",
    "    return\n",
    "    \n",
    "\n",
    "#upload_file()\n",
    "game_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100263: Petrobras Distribuidora SA\n",
      "100264: Universal Health Services Inc\n",
      "100266: Tenet Healthcare Corp\n",
      "100267: U.S. High Yield\n",
      "200286: Generali\n",
      "200291: BASF SE\n",
      "200292: Asos\n",
      "300016: Nidec\n",
      "300022: Murata Manufacturing\n",
      "300023: Sydney Airport\n",
      "300025: New Oriental Education & Technology\n",
      "300028: Nintendo\n",
      "300029: Telkom Indonesia\n",
      "300031: China Mobile\n",
      "300032: Largan Precision\n",
      "300033: Ping An Insurance\n",
      "300034: Woodside Petroleum Limited\n",
      "300035: Mirvac Group\n",
      "    index      id                                       title  \\\n",
      "0       0  100263       Petrobras Distribuidora SA (BRDT3.SA)   \n",
      "1       6  100264       Universal Health Services Inc (UHS.N)   \n",
      "2      12  100266               Tenet Healthcare Corp (THC.N)   \n",
      "3      18  100267                      U.S. High Yield (USHY)   \n",
      "4      24  200286                          Generali (GASI.MI)   \n",
      "5      30  200291                          BASF SE (BASFn.DE)   \n",
      "6      36  200292                               Asos (ASOS.L)   \n",
      "7      42  300016                              Nidec (6594.T)   \n",
      "8      48  300022               Murata Manufacturing (6981.T)   \n",
      "9      54  300023                     Sydney Airport (SYD.AX)   \n",
      "10     60  300025  New Oriental Education & Technology(EDU.N)   \n",
      "11     66  300028                            Nintendo(7974.T)   \n",
      "12     72  300029                   Telkom Indonesia(TLKM.JK)   \n",
      "13     78  300031             China Mobile (HK) Ltd (0941.HK)   \n",
      "14     84  300032                  Largan Precision (3008.TW)   \n",
      "15     90  300033          Ping An Insurance (Group)(2318.HK)   \n",
      "16     96  300034         Woodside Petroleum Limited (WPL.AX)   \n",
      "17    102  300035                       Mirvac Group (MGR.AX)   \n",
      "\n",
      "                              new_title  \n",
      "0            Petrobras Distribuidora SA  \n",
      "1         Universal Health Services Inc  \n",
      "2                 Tenet Healthcare Corp  \n",
      "3                       U.S. High Yield  \n",
      "4                              Generali  \n",
      "5                               BASF SE  \n",
      "6                                  Asos  \n",
      "7                                 Nidec  \n",
      "8                  Murata Manufacturing  \n",
      "9                        Sydney Airport  \n",
      "10  New Oriental Education & Technology  \n",
      "11                             Nintendo  \n",
      "12                     Telkom Indonesia  \n",
      "13                         China Mobile  \n",
      "14                     Largan Precision  \n",
      "15                    Ping An Insurance  \n",
      "16           Woodside Petroleum Limited  \n",
      "17                         Mirvac Group  \n"
     ]
    }
   ],
   "source": [
    "#MTG Data Asset Preparation\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "class MTG_Data:\n",
    "    def __init__(self, path):\n",
    "         self.path=path\n",
    "                    \n",
    "\n",
    "    def csv_create(self):\n",
    "        files=os.listdir(self.path)\n",
    "        filename = [filename for filename in files if filename.startswith('Data_GameID')]\n",
    "\n",
    "        for datafile in filename:\n",
    "            df=pd.read_csv(datafile)\n",
    "            name = os.path.splitext(datafile)[0]\n",
    "            df.to_csv(name+'_Raw'+'.csv',index=False)\n",
    "            df=df.drop('other_issues',axis=1)\n",
    "            df.to_csv(datafile,index=False)\n",
    "        return\n",
    "\n",
    "    def column_change(self):\n",
    "        allfiles = os.listdir(self.path)\n",
    "\n",
    "        game=pd.read_csv('Games For This Week.csv').dropna(axis=0)\n",
    "        game_list=game['id'].unique().tolist()\n",
    "\n",
    "        for game_id in game_list:\n",
    "            filename = [f for f in allfiles if re.search(r'(%s_\\d{4}-\\d{2}-\\d{2}\\.csv$)'%(game_id), f)]\n",
    "            for file in filename:\n",
    "     \n",
    "                df=pd.read_csv(file)\n",
    "                new_name=game.loc[game['id'] == game_id]['issues'].tolist()\n",
    "                df.rename(columns=dict(zip(df.columns[2:7],new_name)),inplace=True)\n",
    "                df.to_csv(file,index=False)\n",
    "        return\n",
    "    \n",
    "    def AC_file(self):\n",
    "        allfiles = os.listdir(self.path)\n",
    "        \n",
    "        files = [f for f in allfiles if re.search(r'(-\\d{2}\\.csv$)', f) and f.startswith('Data_GameID_')]\n",
    "        open('AC text file.txt', 'w').close()  #Clear the content of existing file\n",
    "\n",
    "        mydata=pd.DataFrame()\n",
    "        for filename in files:\n",
    "            df = pd.read_csv(filename,index_col=0)\n",
    "            df.rename(columns=dict(zip(df.columns[1:6],['A','B','C','D','E'])),inplace=True)\n",
    "            mydata=mydata.append(df,sort=False)\n",
    "\n",
    "        mydata.to_csv(r'AC text file.txt',header=True,sep='\\t',mode='a')\n",
    "        mydata.to_csv('template.csv',index_label='Date_Time')\n",
    "        return\n",
    "    \n",
    "    def replace(self):\n",
    "        files = os.listdir(self.path)\n",
    "        filename = [filename for filename in files if filename.startswith('Links_')]\n",
    "    #os.path.splitext(filename)[0]\n",
    "        for doc in filename:\n",
    "            df=pd.read_csv(doc).iloc[0,0]\n",
    "        \n",
    "            Game_id=re.search(r'(id=\\d{6}&)',df).group()[3:9]\n",
    "    \n",
    "            n_filename=re.search(r'(\\w{5}_\\d{4}-\\d{2}-\\d{2})',doc).group()\\\n",
    "               +'_'+Game_id+'.csv'\n",
    "\n",
    "            os.rename(doc,n_filename)\n",
    "            #print(Game_id)\n",
    "        return\n",
    "    \n",
    "    def add_links(self): \n",
    "        files = os.listdir(self.path)\n",
    "        filename = [filename for filename in files if filename.startswith('Links_')]\n",
    "        New_value=['Y5135615153446832','X6C79644456466554','X6B7867554F566343','X687749594E315644'\\\n",
    "                   ,'X5747465A46784231','X5646515641435143']\n",
    "        \n",
    "        for doc in filename:\n",
    "            New_list=[]\n",
    "            df=pd.read_csv(doc).iloc[:,0].tolist()\n",
    "            Mylink=df[-1] \n",
    "\n",
    "            for i in New_value:\n",
    "                a=Mylink.replace(Mylink[Mylink.index('&ma=')+4:],i)\n",
    "                New_list.append(a)\n",
    "\n",
    "            df=pd.DataFrame(df+New_list,columns=['Links']).set_index('Links')\n",
    "\n",
    "            df.to_csv(doc)\n",
    "        return\n",
    "    \n",
    "    def joson_file(self):\n",
    "        wd = os.getcwd()\n",
    "        allfiles = os.listdir(self.path)\n",
    "\n",
    "        game=pd.read_csv('Games For This Week.csv').dropna(axis=0).set_index('issues')\n",
    "\n",
    "        results_json = [f for f in allfiles if f.endswith('.json')]\n",
    "        \n",
    "        for i in results_json: \n",
    "            with open(i, 'r') as filename:\n",
    "                json_file=json.load(filename)\n",
    "                df =pd.DataFrame(json_file['issues'],columns=['issues'])\n",
    "                data=df.merge(game,on='issues')\n",
    "                x=data['id'].value_counts().sort_values(ascending=False).index.tolist()[0]\n",
    "                game_id=str(x)\n",
    "                #game_id=data.iloc[0,1].astype(str)\n",
    "       \n",
    "                try:\n",
    "                    pos=data.iloc[0,2].index('(')\n",
    "                except:\n",
    "                    pos=len(data.iloc[0,2])\n",
    "            \n",
    "                new_name=data.iloc[0,2][:pos]\n",
    "                \n",
    "               \n",
    "                #print(game_id)\n",
    "                #print(new_name)\n",
    "                filename.close()\n",
    "                \n",
    "            os.rename(i,game_id+'.json')\n",
    "            srcname =os.path.join(wd,game_id+'.json')\n",
    "            detname=os.path.join(wd,game_id)\n",
    "            shutil.move(srcname,detname)\n",
    "         \n",
    "        \n",
    "            csv_files = [\n",
    "                       filename for filename in allfiles if filename.endswith('.csv')\n",
    "                       and (re.search((r'%s' % game_id), filename))\n",
    "                ]\n",
    "\n",
    "            for j in csv_files:\n",
    "                srcname_1=os.path.join(wd,j)\n",
    "                shutil.move(srcname_1,detname)\n",
    "                \n",
    "        return\n",
    "\n",
    "            #for retry in range(50):\n",
    "            #    try:\n",
    "            #        shutil.move(game_id,new_name)\n",
    "            #        break\n",
    "            #    except:\n",
    "            #        print(\"rename failed, retrying...\")\n",
    "        \n",
    "    def change_folder(self):\n",
    "        wd = os.getcwd()\n",
    "        allfiles = os.listdir('.')\n",
    "\n",
    "        df=pd.read_csv('Games For This Week.csv').dropna(axis=0).loc[:,['id','title']].drop_duplicates(subset=['id', 'title'])\\\n",
    "        .reset_index()\n",
    "        \n",
    "        df['id']=df['id'].astype(str)\n",
    "\n",
    "        df['new_title']=df.title.apply(lambda s: s.split( '(', 1 )[ 0 ].strip())\n",
    "        #df['new_title']=df.title.str.replace(r\"\\(.*\\)\",\"\")\n",
    "\n",
    "        dict1=dict(zip(df.id.tolist(),df.new_title.tolist()))\n",
    "\n",
    "        for k, v in dict1.items():\n",
    "            print(\"{0}: {1}\".format(k,v))\n",
    "            shutil.move(os.path.join(wd,k),os.path.join(wd,v))\n",
    "            \n",
    "        print(df)\n",
    "        \n",
    "        return\n",
    "    \n",
    "if __name__ == '__main__':  \n",
    "    mtg=MTG_Data('.')\n",
    "    mtg.csv_create()\n",
    "    mtg.column_change()\n",
    "    mtg.AC_file()\n",
    "    mtg.replace()\n",
    "    mtg.add_links()\n",
    "    mtg.joson_file()\n",
    "    mtg.change_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
